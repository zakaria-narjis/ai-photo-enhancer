{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "with open(\"configs/hyperparameters.yaml\") as f:\n",
    "    config_dict =yaml.load(f, Loader=yaml.FullLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding testing data ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d54559a3c4b456dafefacd863e0a901",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished...\n",
      "Encoding training data ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5656cbd6d5544a4b6bf10bf1a256cc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/36 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished...\n"
     ]
    }
   ],
   "source": [
    "from envs.photo_env import PhotoEnhancementEnv\n",
    "env = PhotoEnhancementEnv(64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config(object):\n",
    "    def __init__(self, dictionary):\n",
    "        self.__dict__.update(dictionary)\n",
    "sac_config = Config(config_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "SEED = sac_config.seed\n",
    "DEVICE= 'CUDA'\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = sac_config.torch_deterministic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import time\n",
    "run_name = f\"{sac_config.exp_name}__{sac_config.seed}__{int(time.time())}\"\n",
    "writer = SummaryWriter(f\"runs/{run_name}\")\n",
    "writer.add_text(\n",
    "    \"hyperparameters\",\n",
    "    \"|param|value|\\n|-|-|\\n%s\" % (\"\\n\".join([f\"|{key}|{value}|\" for key, value in vars(sac_config).items()])),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zakaria/miniconda3/envs/photoen/lib/python3.11/site-packages/torchrl/__init__.py:36: UserWarning: failed to set start method to spawn, and current start method for mp is fork.\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "from sac.sac_algorithm import SAC\n",
    "import multiprocessing as mp\n",
    "try:\n",
    "    mp.set_start_method('spawn', force=True)\n",
    "except RuntimeError:\n",
    "    pass  \n",
    "\n",
    "agent = SAC(env,sac_config,writer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPS: 67\n",
      "SPS: 84\n",
      "SPS: 138\n",
      "SPS: 146\n",
      "SPS: 188\n",
      "SPS: 180\n",
      "SPS: 260\n",
      "SPS: 296\n",
      "SPS: 300\n",
      "SPS: 253\n",
      "SPS: 333\n",
      "SPS: 331\n",
      "SPS: 425\n",
      "SPS: 362\n",
      "SPS: 372\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m episode_count\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m      9\u001b[0m agent\u001b[38;5;241m.\u001b[39mglobal_step\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m---> 10\u001b[0m mean_reward,batch_dones \u001b[38;5;241m=\u001b[39m \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m envs_mean_rewards\u001b[38;5;241m.\u001b[39mappend(mean_reward)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (batch_dones\u001b[38;5;241m==\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\u001b[38;5;241m.\u001b[39mall()\u001b[38;5;241m==\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m episode_count\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m10\u001b[39m:\n",
      "File \u001b[0;32m~/workspace/ai-photo-enhancer/sac/sac_algorithm.py:96\u001b[0m, in \u001b[0;36mSAC.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     93\u001b[0m     actions \u001b[38;5;241m=\u001b[39m actions\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\n\u001b[1;32m     95\u001b[0m \u001b[38;5;66;03m# TRY NOT TO MODIFY: execute the game and log data.\u001b[39;00m\n\u001b[0;32m---> 96\u001b[0m next_batch_obs, rewards, dones \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mactions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;66;03m# # TRY NOT TO MODIFY: record rewards for plotting purposes\u001b[39;00m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;66;03m# if \"final_info\" in infos:\u001b[39;00m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;66;03m#     for info in infos[\"final_info\"]:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;66;03m#     if trunc:\u001b[39;00m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;66;03m#         real_next_obs[idx] = infos[\"final_observation\"][idx]\u001b[39;00m\n\u001b[1;32m    112\u001b[0m batch_transition \u001b[38;5;241m=\u001b[39m TensorDict(\n\u001b[1;32m    113\u001b[0m     {\n\u001b[1;32m    114\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobservations\u001b[39m\u001b[38;5;124m\"\u001b[39m:batch_obs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    120\u001b[0m     batch_size \u001b[38;5;241m=\u001b[39m [batch_obs\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]],\n\u001b[1;32m    121\u001b[0m )\n",
      "File \u001b[0;32m~/workspace/ai-photo-enhancer/envs/photo_env.py:255\u001b[0m, in \u001b[0;36mPhotoEnhancementEnv.step\u001b[0;34m(self, batch_actions)\u001b[0m\n\u001b[1;32m    252\u001b[0m source_images \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msource_image\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m255.0\u001b[39m \u001b[38;5;66;03m# batch of images that have to be enhanced\u001b[39;00m\n\u001b[1;32m    253\u001b[0m \u001b[38;5;66;03m# actions =  torch.index_select(batch_actions,0,self.sub_env_running)\u001b[39;00m\n\u001b[0;32m--> 255\u001b[0m enhanced_image \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mphoto_editor\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource_images\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpermute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mbatch_actions\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m#(B,H,W,3)\u001b[39;00m\n\u001b[1;32m    256\u001b[0m enhanced_image \u001b[38;5;241m=\u001b[39m enhanced_image\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m) \n\u001b[1;32m    257\u001b[0m encoded_enhanced_image \u001b[38;5;241m=\u001b[39m image_encoder\u001b[38;5;241m.\u001b[39mencode(enhanced_image)\u001b[38;5;241m.\u001b[39mcpu()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(sac_config.total_timesteps):\n",
    "    episode_count = 0\n",
    "    agent.start_time = time.time()\n",
    "    agent.reset_env()\n",
    "    envs_mean_rewards =[]\n",
    "    while True:\n",
    "\n",
    "        episode_count+=1\n",
    "        agent.global_step+=1\n",
    "        mean_reward,batch_dones = agent.train()\n",
    "        envs_mean_rewards.append(mean_reward)\n",
    "\n",
    "        if (batch_dones==True).all()==True or episode_count==10:\n",
    "            ens_mean_episodic_return = sum(envs_mean_rewards)\n",
    "            agent.writer.add_scalar(\"charts/episodic_return\", ens_mean_episodic_return, agent.global_step)\n",
    "            episode_count=0\n",
    "            envs_mean_rewards =[]\n",
    "            agent.reset_env()\n",
    "            break     "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "photoen",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
