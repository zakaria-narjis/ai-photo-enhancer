{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding testing data ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "834a762585554a868866e962698506bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished...\n",
      "Encoding training data ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe9f7b2bc5824b07acaf2c39a998ab92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/36 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zakaria/miniconda3/envs/photoen/lib/python3.11/site-packages/torchrl/__init__.py:36: UserWarning: failed to set start method to spawn, and current start method for mp is fork.\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import time\n",
    "from envs.photo_env import PhotoEnhancementEnv\n",
    "from sac.sac_algorithm import SAC\n",
    "import multiprocessing as mp\n",
    "try:\n",
    "    mp.set_start_method('spawn', force=True)\n",
    "except RuntimeError:\n",
    "    pass  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = PhotoEnhancementEnv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"configs/hyperparameters.yaml\") as f:\n",
    "    config_dict =yaml.load(f, Loader=yaml.FullLoader)\n",
    "    \n",
    "class Config(object):\n",
    "    def __init__(self, dictionary):\n",
    "        self.__dict__.update(dictionary)\n",
    "sac_config = Config(config_dict)\n",
    "\n",
    "SEED = sac_config.seed\n",
    "DEVICE= 'CUDA'\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = sac_config.torch_deterministic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_name = f\"{sac_config.exp_name}__{sac_config.seed}__{int(time.time())}\"\n",
    "writer = SummaryWriter(f\"runs/{run_name}\")\n",
    "writer.add_text(\n",
    "    \"hyperparameters\",\n",
    "    \"|param|value|\\n|-|-|\\n%s\" % (\"\\n\".join([f\"|{key}|{value}|\" for key, value in vars(sac_config).items()])),\n",
    ")\n",
    "agent = SAC(env,sac_config,writer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPS: 1\n",
      "SPS: 1\n",
      "SPS: 1\n",
      "SPS: 1\n",
      "SPS: 1\n",
      "SPS: 1\n",
      "SPS: 1\n",
      "SPS: 1\n",
      "SPS: 1\n",
      "SPS: 1\n",
      "SPS: 1\n",
      "SPS: 1\n",
      "SPS: 1\n",
      "SPS: 1\n",
      "SPS: 1\n",
      "SPS: 1\n",
      "SPS: 1\n",
      "SPS: 1\n",
      "SPS: 1\n",
      "SPS: 1\n",
      "SPS: 1\n",
      "SPS: 1\n",
      "SPS: 1\n",
      "SPS: 1\n",
      "SPS: 1\n",
      "one done\n",
      "torch.Size([127, 1024]) torch.Size([127])\n",
      "tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  51,  52,  53,  54,  55,  56,\n",
      "         57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,  70,\n",
      "         71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,  84,\n",
      "         85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,\n",
      "         99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112,\n",
      "        113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126,\n",
      "        127], dtype=torch.int32)\n",
      "d tensor([[0.0190, 0.5916, 0.6648,  ..., 0.6077, 1.6807, 0.4914],\n",
      "        [0.4188, 0.4327, 3.8278,  ..., 2.3976, 0.0000, 0.0000],\n",
      "        [2.5445, 0.0000, 1.2253,  ..., 3.2964, 6.1631, 2.0435],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.4454,  ..., 4.4350, 8.4690, 0.0000],\n",
      "        [0.3719, 0.0000, 0.3776,  ..., 0.4103, 0.0389, 0.0000],\n",
      "        [0.8829, 0.9674, 8.1201,  ..., 7.0078, 0.0000, 0.0000]],\n",
      "       device='cuda:0') tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  51,  52,  53,  54,  55,  56,\n",
      "         57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,  70,\n",
      "         71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,  84,\n",
      "         85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,\n",
      "         99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112,\n",
      "        113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126,\n",
      "        127], dtype=torch.int32)\n",
      "torch.Size([127, 1024]) torch.Size([127])\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index out of range in self",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m episode_count\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m      9\u001b[0m agent\u001b[38;5;241m.\u001b[39mglobal_step\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m---> 10\u001b[0m mean_reward,batch_dones \u001b[38;5;241m=\u001b[39m \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m envs_mean_rewards\u001b[38;5;241m.\u001b[39mappend(mean_reward)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m(batch_dones\u001b[38;5;241m==\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\u001b[38;5;241m.\u001b[39many():\n",
      "File \u001b[0;32m~/workspace/ai-photo-enhancer/sac/sac_algorithm.py:100\u001b[0m, in \u001b[0;36mSAC.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrb\u001b[38;5;241m.\u001b[39mextend(batch_transition)\n\u001b[1;32m     99\u001b[0m runing_envs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv\u001b[38;5;241m.\u001b[39msub_env_running \n\u001b[0;32m--> 100\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m=\u001b[39m  \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex_select\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnext_batch_obs\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mruning_envs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m    102\u001b[0m \u001b[38;5;66;03m# ALGO LOGIC: training.\u001b[39;00m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mlearning_starts:\n",
      "\u001b[0;31mIndexError\u001b[0m: index out of range in self"
     ]
    }
   ],
   "source": [
    "agent.start_time = time.time()\n",
    "for i in range(sac_config.total_timesteps):\n",
    "    episode_count = 0\n",
    "    \n",
    "    agent.reset_env()\n",
    "    envs_mean_rewards =[]\n",
    "    while True:     \n",
    "        episode_count+=1\n",
    "        agent.global_step+=1\n",
    "        mean_reward,batch_dones = agent.train()\n",
    "        envs_mean_rewards.append(mean_reward)\n",
    "        if(batch_dones==True).any():\n",
    "            print('one done')\n",
    "            print(agent.state.shape,agent.env.sub_env_running.shape)\n",
    "            print(agent.env.sub_env_running)\n",
    "        if (batch_dones==True).all()==True or episode_count==sac_config.max_episode_timesteps:\n",
    "            ens_mean_episodic_return = sum(envs_mean_rewards)\n",
    "            if agent.global_step % 100 == 0:\n",
    "                agent.writer.add_scalar(\"charts/episodic_return\", ens_mean_episodic_return, agent.global_step)\n",
    "                envs_mean_rewards =[]\n",
    "            episode_count=0           \n",
    "            agent.reset_env()\n",
    "            break     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index out of range in self",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 12\u001b[0m\n\u001b[1;32m      1\u001b[0m f\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mtensor([  \u001b[38;5;241m0\u001b[39m,   \u001b[38;5;241m1\u001b[39m,   \u001b[38;5;241m2\u001b[39m,   \u001b[38;5;241m3\u001b[39m,   \u001b[38;5;241m4\u001b[39m,   \u001b[38;5;241m5\u001b[39m,   \u001b[38;5;241m6\u001b[39m,   \u001b[38;5;241m7\u001b[39m,   \u001b[38;5;241m8\u001b[39m,   \u001b[38;5;241m9\u001b[39m,  \u001b[38;5;241m10\u001b[39m,  \u001b[38;5;241m11\u001b[39m,  \u001b[38;5;241m12\u001b[39m,  \u001b[38;5;241m13\u001b[39m,\n\u001b[1;32m      2\u001b[0m          \u001b[38;5;241m14\u001b[39m,  \u001b[38;5;241m15\u001b[39m,  \u001b[38;5;241m16\u001b[39m,  \u001b[38;5;241m17\u001b[39m,  \u001b[38;5;241m18\u001b[39m,  \u001b[38;5;241m19\u001b[39m,  \u001b[38;5;241m20\u001b[39m,  \u001b[38;5;241m21\u001b[39m,  \u001b[38;5;241m22\u001b[39m,  \u001b[38;5;241m23\u001b[39m,  \u001b[38;5;241m24\u001b[39m,  \u001b[38;5;241m25\u001b[39m,  \u001b[38;5;241m26\u001b[39m,  \u001b[38;5;241m27\u001b[39m,\n\u001b[1;32m      3\u001b[0m          \u001b[38;5;241m28\u001b[39m,  \u001b[38;5;241m29\u001b[39m,  \u001b[38;5;241m30\u001b[39m,  \u001b[38;5;241m31\u001b[39m,  \u001b[38;5;241m32\u001b[39m,  \u001b[38;5;241m33\u001b[39m,  \u001b[38;5;241m34\u001b[39m,  \u001b[38;5;241m35\u001b[39m,  \u001b[38;5;241m36\u001b[39m,  \u001b[38;5;241m37\u001b[39m,  \u001b[38;5;241m38\u001b[39m,  \u001b[38;5;241m39\u001b[39m,  \u001b[38;5;241m40\u001b[39m,  \u001b[38;5;241m41\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[38;5;241m113\u001b[39m, \u001b[38;5;241m114\u001b[39m, \u001b[38;5;241m115\u001b[39m, \u001b[38;5;241m116\u001b[39m, \u001b[38;5;241m117\u001b[39m, \u001b[38;5;241m118\u001b[39m, \u001b[38;5;241m119\u001b[39m, \u001b[38;5;241m120\u001b[39m, \u001b[38;5;241m121\u001b[39m, \u001b[38;5;241m122\u001b[39m, \u001b[38;5;241m123\u001b[39m, \u001b[38;5;241m124\u001b[39m, \u001b[38;5;241m125\u001b[39m, \u001b[38;5;241m126\u001b[39m,\n\u001b[1;32m     10\u001b[0m         \u001b[38;5;241m127\u001b[39m], dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mint32)\n\u001b[1;32m     11\u001b[0m k\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mrand(\u001b[38;5;241m127\u001b[39m,\u001b[38;5;241m1024\u001b[39m)\n\u001b[0;32m---> 12\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex_select\u001b[49m\u001b[43m(\u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mIndexError\u001b[0m: index out of range in self"
     ]
    }
   ],
   "source": [
    "f=torch.tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
    "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
    "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
    "         42,  43,  44,  45,  46,  47,  48,  49,  51,  52,  53,  54,  55,  56,\n",
    "         57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,  70,\n",
    "         71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,  84,\n",
    "         85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,\n",
    "         99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112,\n",
    "        113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126,\n",
    "        127], dtype=torch.int32)\n",
    "k=torch.rand(127,1024)\n",
    "torch.index_select(k,0,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([127, 1024])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torch\n",
    "image = cv2.imread(\"sample_images/a0676-kme_609 copy.jpg\")\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) \n",
    "input = cv2.resize(image, (64, 64)) / 255.0\n",
    "input = torch.Tensor(input).permute(2,0,1).unsqueeze(0)\n",
    "enhanced_image = input.clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from envs.features_extractor import ResnetEncoder\n",
    "from envs.new_edit_photo import PhotoEditor\n",
    "import matplotlib.pyplot as plt\n",
    "photo_editor = PhotoEditor()\n",
    "image_encoder = ResnetEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_source = image_encoder.encode(input)\n",
    "original_64 = input.permute(0,2,3,1)\n",
    "original_image = torch.Tensor(image).unsqueeze(0)/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = torch.tensor([0.125, 0.125, 0.375, 0.125, 0., 0.0625, 0.9375, 0.375, 0.0625, 0., 0.125, 0.125]).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enhanced_image=enhanced_image.permute(0,2,3,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enhanced_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    with torch.no_grad():\n",
    "        encoded_enhanced = image_encoder.encode(enhanced_image.permute(0,3,1,2))\n",
    "        encoded_input = torch.cat([encoded_source,encoded_enhanced],dim=1)\n",
    "        parameters = agent.actor.get_action(encoded_input)\n",
    "        enhanced_image = photo_editor(original_64.cpu(),parameters[0].cpu())\n",
    "enhanced_image_512 = photo_editor(original_image.cpu(),parameters[0].cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enhanced_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enhanced_image_512.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enhanced_image_512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enhanced =torch.flatten(enhanced_image_512.clone(),start_dim=1, end_dim=-1)\n",
    "target = torch.flatten(original_image.clone(),start_dim=1, end_dim=-1)\n",
    "\n",
    "rmse = enhanced-target\n",
    "rmse = torch.pow(rmse,2).mean(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(enhanced_image_512[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "photoen",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
