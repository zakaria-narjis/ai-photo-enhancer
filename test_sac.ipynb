{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import time\n",
    "from envs.photo_env import PhotoEnhancementEnv\n",
    "from envs.photo_env import PhotoEnhancementEnvTest\n",
    "from sac.sac_algorithm import SAC\n",
    "import multiprocessing as mp\n",
    "try:\n",
    "    mp.set_start_method('spawn', force=True)\n",
    "except RuntimeError:\n",
    "    pass  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.anomaly_mode.set_detect_anomaly at 0x7e81d6bb6b10>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"configs/hyperparameters.yaml\") as f:\n",
    "    config_dict =yaml.load(f, Loader=yaml.FullLoader)\n",
    "\n",
    "with open(\"configs/config.yaml\") as f:\n",
    "    env_config_dict =yaml.load(f, Loader=yaml.FullLoader)\n",
    "    \n",
    "class Config(object):\n",
    "    def __init__(self, dictionary):\n",
    "        self.__dict__.update(dictionary)\n",
    "sac_config = Config(config_dict)\n",
    "env_config = Config(env_config_dict)\n",
    "SEED = sac_config.seed\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = sac_config.torch_deterministic\n",
    "torch.autograd.set_detect_anomaly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sliders used ['contrast', 'exposure', 'shadows', 'highlights', 'whites']\n",
      "Number of sliders used 5\n",
      "Sliders used ['contrast', 'exposure', 'shadows', 'highlights', 'whites']\n",
      "Number of sliders used 5\n"
     ]
    }
   ],
   "source": [
    "env = PhotoEnhancementEnv(\n",
    "                    batch_size=env_config.train_batch_size,\n",
    "                    imsize=env_config.imsize,\n",
    "                    training_mode=True,\n",
    "                    done_threshold=env_config.threshold_psnr,\n",
    "                    pre_encode=False,\n",
    "                    edit_sliders=env_config.sliders_to_use,\n",
    "                    features_size=env_config.features_size,\n",
    "                    logger=None\n",
    ")\n",
    "test_env = PhotoEnhancementEnvTest(\n",
    "                    batch_size=env_config.test_batch_size,\n",
    "                    imsize=env_config.imsize,\n",
    "                    training_mode=False,\n",
    "                    done_threshold=env_config.threshold_psnr,\n",
    "                    pre_encode=False,\n",
    "                    edit_sliders=env_config.sliders_to_use,\n",
    "                    features_size=env_config.features_size,\n",
    "                    logger=None\n",
    ")\n",
    "print(f'Sliders used {env.edit_sliders}')\n",
    "print(f'Number of sliders used { env.num_parameters}')\n",
    "print(f'Sliders used {test_env .edit_sliders}')\n",
    "print(f'Number of sliders used {test_env .num_parameters}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 5) -5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zakaria/miniconda3/envs/photoen/lib/python3.11/site-packages/torch/_compile.py:24: UserWarning: optimizer contains a parameter group with duplicate parameters; in future, this will cause an error; see github.com/pytorch/pytorch/issues/40967 for more information\n",
      "  return torch._dynamo.disable(fn, recursive)(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "run_name = f\"{sac_config.exp_name}__{sac_config.seed}__{int(time.time())}\"\n",
    "writer = SummaryWriter(f\"runs/{run_name}\")\n",
    "writer.add_text(\n",
    "    \"hyperparameters\",\n",
    "    \"|param|value|\\n|-|-|\\n%s\" % (\"\\n\".join([f\"|{key}|{value}|\" for key, value in vars(sac_config).items()])),\n",
    ")\n",
    "agent = SAC(env,sac_config,writer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-07 11:48:02.692269\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "c = datetime.now()\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2024-07-07_11:48:04.75'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# Get the current time\n",
    "c = datetime.now()\n",
    "\n",
    "# Round the seconds to two decimal places\n",
    "rounded_seconds = round(c.second + c.microsecond / 1e6, 2)\n",
    "\n",
    "# Create a new datetime string with the rounded seconds\n",
    "formatted_time = c.strftime('%Y-%m-%d_%H:%M:') + f'{rounded_seconds:05.2f}'\n",
    "\n",
    "formatted_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.start_time = time.time()\n",
    "for i in range(1):\n",
    "    episode_count = 0\n",
    "    \n",
    "    agent.reset_env()\n",
    "    envs_mean_rewards =[]\n",
    "    while True:     \n",
    "        episode_count+=1\n",
    "        agent.global_step+=1\n",
    "        rewards,batch_dones = agent.train()\n",
    "        envs_mean_rewards.append(rewards.mean().item())\n",
    "        if(batch_dones==True).any():\n",
    "            # print('one done')\n",
    "            # print(agent.state.shape,agent.env.sub_env_running.shape)\n",
    "            num_env_done = int(batch_dones.sum().item())\n",
    "            agent.writer.add_scalar(\"charts/num_env_done\", num_env_done , agent.global_step)\n",
    "        if agent.global_step % 100 == 0:\n",
    "            ens_mean_episodic_return = sum(envs_mean_rewards)\n",
    "            agent.writer.add_scalar(\"charts/mean_episodic_return\", ens_mean_episodic_return, agent.global_step)\n",
    "\n",
    "        if (batch_dones==True).all()==True or episode_count==sac_config.max_episode_timesteps:\n",
    "            episode_count=0           \n",
    "            break \n",
    "\n",
    "    if agent.global_step%200==0:\n",
    "        # agent.backbone.eval()\n",
    "        # with torch.no_grad():\n",
    "        #     n_images = 5\n",
    "        #     obs = test_env.reset() \n",
    "        #     actions = agent.actor.get_action(obs.to(sac_config.device))\n",
    "        #     _,rewards,dones = test_env.step(actions[0].cpu())\n",
    "        #     agent.writer.add_scalar(\"charts/test_mean_episodic_return\", rewards.mean().item(), agent.global_step)\n",
    "        #     agent.writer.add_images(\"test_images\",test_env.state['source_image'][:n_images],0)\n",
    "        #     agent.writer.add_images(\"test_images\",test_env.state['enhanced_image'][:n_images],1)\n",
    "        #     agent.writer.add_images(\"test_images\",test_env.state['target_image'][:n_images],2)\n",
    "        # agent.backbone.train()\n",
    "        n_images = 5\n",
    "        obs = test_env.reset() \n",
    "        actions = agent.act_eval(obs)\n",
    "        _,rewards,dones = test_env.step(actions[0].cpu())\n",
    "        agent.writer.add_scalar(\"charts/test_mean_episodic_return\", rewards.mean().item(), agent.global_step)\n",
    "        agent.writer.add_images(\"test_images\",test_env.state['source_image'][:n_images],0)\n",
    "        agent.writer.add_images(\"test_images\",test_env.state['enhanced_image'][:n_images],1)\n",
    "        agent.writer.add_images(\"test_images\",test_env.state['target_image'][:n_images],2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# torch.nn.Sequential(*(list(agent.actor.children())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "source_image = cv2.imread(\"sample_images/a0676-kme_609_original.jpg\")\n",
    "target_image = cv2.imread(\"sample_images/a0676-kme_609_C.jpg\")\n",
    "source_image = cv2.cvtColor(source_image, cv2.COLOR_BGR2RGB) /255.0\n",
    "target_image = cv2.cvtColor(target_image, cv2.COLOR_BGR2RGB) /255.0\n",
    "\n",
    "input = torch.Tensor(source_image).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(source_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SLIDERS_TO_USE = [\"contrast\",\"exposure\",\"shadows\",\"highlights\",\"whites\"]\n",
    "from envs.new_edit_photo import PhotoEditor\n",
    "import matplotlib.pyplot as plt\n",
    "photo_editor = PhotoEditor(SLIDERS_TO_USE)\n",
    "photo_editor_UIE = PhotoEditor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_UIE = torch.tensor([0.125, 0.125, 0.375, 0.125, 0., 0.0625, 0.9375, 0.375, 0.0625, 0., 0.125, 0.125]).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.backbone.eval()\n",
    "agent.actor.eval()\n",
    "with torch.no_grad():\n",
    "    parameters = agent.actor.get_action(input.permute(0,3,1,2).cuda())\n",
    "    enhanced_image = photo_editor(input.cpu(),parameters[0].cpu())\n",
    "    enhanced_image_UIE = photo_editor_UIE(input.cpu(),param_UIE.cpu())\n",
    "parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_tensor = torch.Tensor(target_image).unsqueeze(0)\n",
    "PSNR_UIE = test_env.compute_rewards(enhanced_image_UIE,target_tensor).item()+50\n",
    "PSNR_OURS = test_env.compute_rewards(enhanced_image,target_tensor).item()+50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 4, figsize=(15, 5))\n",
    "labels =[\"Source_Image\",\"Enhanced_Image(ours)\",\"Enhanced_Image(UIE)\",\"Target_Image\"]\n",
    "imgs =[source_image,enhanced_image[0],enhanced_image_UIE[0],target_image]\n",
    "PSNRS = [PSNR_OURS,PSNR_UIE]\n",
    "for index,(img,label) in enumerate(zip(imgs,labels)):\n",
    "    axes[index].imshow(img)\n",
    "    axes[index].set_title(label)\n",
    "    axes[index].axis('off')\n",
    "    if index==1 or index==2:\n",
    "        axes[index].text(0.5, -0.1, f'PSNR:{round(PSNRS[index-1],2)}', size=12, ha='center', transform=axes[index].transAxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(agent.actor.state_dict(), 'actor_model_5param.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "photoen",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
