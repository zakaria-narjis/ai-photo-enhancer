{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding testing data ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00f968f48f974403a33271e2d479dca5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished...\n",
      "Encoding training data ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed018bf1f27e40b0a92c135d9fc5c342",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/36 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished...\n"
     ]
    },
    {
     "ename": "SyntaxError",
     "evalue": "'(' was never closed (sac_algorithm.py, line 139)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[0;36m(most recent call last)\u001b[0m:\n",
      "\u001b[0m  File \u001b[1;32m~/miniconda3/envs/photoen/lib/python3.11/site-packages/IPython/core/interactiveshell.py:3577\u001b[0m in \u001b[1;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\u001b[0m\n",
      "\u001b[0;36m  Cell \u001b[0;32mIn[1], line 10\u001b[0;36m\n\u001b[0;31m    from sac.sac_algorithm import SAC\u001b[0;36m\n",
      "\u001b[0;36m  File \u001b[0;32m~/workspace/ai-photo-enhancer/sac/sac_algorithm.py:139\u001b[0;36m\u001b[0m\n\u001b[0;31m    (log_pi.detach().requires_grad=False\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m '(' was never closed\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import time\n",
    "from envs.photo_env import PhotoEnhancementEnv\n",
    "from envs.photo_env import PhotoEnhancementEnvTest\n",
    "from sac.sac_algorithm import SAC\n",
    "import multiprocessing as mp\n",
    "try:\n",
    "    mp.set_start_method('spawn', force=True)\n",
    "except RuntimeError:\n",
    "    pass  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = PhotoEnhancementEnv()\n",
    "test_env = PhotoEnhancementEnvTest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.anomaly_mode.set_detect_anomaly at 0x74907310d6d0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"configs/hyperparameters.yaml\") as f:\n",
    "    config_dict =yaml.load(f, Loader=yaml.FullLoader)\n",
    "    \n",
    "class Config(object):\n",
    "    def __init__(self, dictionary):\n",
    "        self.__dict__.update(dictionary)\n",
    "sac_config = Config(config_dict)\n",
    "\n",
    "SEED = sac_config.seed\n",
    "DEVICE= 'CUDA'\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = sac_config.torch_deterministic\n",
    "torch.autograd.set_detect_anomaly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 12) -12\n"
     ]
    }
   ],
   "source": [
    "run_name = f\"{sac_config.exp_name}__{sac_config.seed}__{int(time.time())}\"\n",
    "writer = SummaryWriter(f\"runs/{run_name}\")\n",
    "writer.add_text(\n",
    "    \"hyperparameters\",\n",
    "    \"|param|value|\\n|-|-|\\n%s\" % (\"\\n\".join([f\"|{key}|{value}|\" for key, value in vars(sac_config).items()])),\n",
    ")\n",
    "agent = SAC(env,sac_config,writer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "you can only change requires_grad flags of leaf variables. If you want to use a computed variable in a subgraph that doesn't require differentiation use var_no_grad = var.detach().",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m episode_count\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m      9\u001b[0m agent\u001b[38;5;241m.\u001b[39mglobal_step\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m---> 10\u001b[0m mean_reward,batch_dones \u001b[38;5;241m=\u001b[39m \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m envs_mean_rewards\u001b[38;5;241m.\u001b[39mappend(mean_reward)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m(batch_dones\u001b[38;5;241m==\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\u001b[38;5;241m.\u001b[39many():\n",
      "File \u001b[0;32m~/workspace/ai-photo-enhancer/sac/sac_algorithm.py:139\u001b[0m, in \u001b[0;36mSAC.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactor_optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mautotune:\n\u001b[0;32m--> 139\u001b[0m     \u001b[43mlog_pi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequires_grad\u001b[49m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    140\u001b[0m     \u001b[38;5;66;03m# with torch.no_grad():\u001b[39;00m\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;66;03m#     _, log_pi, _ = self.actor.get_action(data[\"observations\"])\u001b[39;00m\n\u001b[1;32m    142\u001b[0m     alpha_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog_alpha\u001b[38;5;241m.\u001b[39mexp() \u001b[38;5;241m*\u001b[39m (log_pi \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_entropy))\u001b[38;5;241m.\u001b[39mmean()\n",
      "\u001b[0;31mRuntimeError\u001b[0m: you can only change requires_grad flags of leaf variables. If you want to use a computed variable in a subgraph that doesn't require differentiation use var_no_grad = var.detach()."
     ]
    }
   ],
   "source": [
    "agent.start_time = time.time()\n",
    "for i in range(sac_config.total_timesteps):\n",
    "    episode_count = 0\n",
    "    \n",
    "    agent.reset_env()\n",
    "    envs_mean_rewards =[]\n",
    "    while True:     \n",
    "        episode_count+=1\n",
    "        agent.global_step+=1\n",
    "        mean_reward,batch_dones = agent.train()\n",
    "        envs_mean_rewards.append(mean_reward)\n",
    "        if(batch_dones==True).any():\n",
    "            print('one done')\n",
    "            print(agent.state.shape,agent.env.sub_env_running.shape)\n",
    "            print(agent.env.sub_env_running)\n",
    "        if (batch_dones==True).all()==True or episode_count==sac_config.max_episode_timesteps:\n",
    "            ens_mean_episodic_return = sum(envs_mean_rewards)\n",
    "            if agent.global_step % 100 == 0:\n",
    "                agent.writer.add_scalar(\"charts/mean_episodic_return\", ens_mean_episodic_return, agent.global_step)\n",
    "                envs_mean_rewards =[]\n",
    "            episode_count=0           \n",
    "            agent.reset_env()\n",
    "            break \n",
    "\n",
    "    if agent.global_step%200==0:\n",
    "        with torch.no_grad():\n",
    "            n_images = 10\n",
    "            obs = test_env.reset() \n",
    "            actions = agent.actor.get_action(obs.to(sac_config.device))\n",
    "            _,rewards,dones = test_env.step(actions[0].cpu())\n",
    "            agent.writer.add_scalar(\"charts/test_mean_episodic_return\", rewards.mean().item(), agent.global_step)\n",
    "            agent.writer.add_images(\"test_images\",test_env.state['source_image'][:n_images],0)\n",
    "            agent.writer.add_images(\"test_images\",test_env.state['enhanced_image'][:n_images],1)\n",
    "            agent.writer.add_images(\"test_images\",test_env.state['target_image'][:n_images],2)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "source_image = cv2.imread(\"sample_images/a0001-jmac_DSC1459.jpg\")\n",
    "target_image = cv2.imread(\"sample_images/a0676-kme_609_C.jpg\")\n",
    "source_image = cv2.cvtColor(source_image, cv2.COLOR_BGR2RGB) \n",
    "target_image = cv2.cvtColor(target_image, cv2.COLOR_BGR2RGB) \n",
    "source_image = cv2.resize(source_image, (64, 64)) / 255.0\n",
    "target_image = cv2.resize(target_image, (64, 64)) / 255.0\n",
    "\n",
    "input = torch.Tensor(source_image).permute(2,0,1).unsqueeze(0)\n",
    "\n",
    "enhanced_image = input.clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(target_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(source_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from envs.features_extractor import ResnetEncoder\n",
    "from envs.new_edit_photo import PhotoEditor\n",
    "import matplotlib.pyplot as plt\n",
    "photo_editor = PhotoEditor()\n",
    "image_encoder = ResnetEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.global_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_source = image_encoder.encode(input)\n",
    "original_64 = input.permute(0,2,3,1)\n",
    "original_image = torch.Tensor(source_image).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = torch.tensor([0.125, 0.125, 0.375, 0.125, 0., 0.0625, 0.9375, 0.375, 0.0625, 0., 0.125, 0.125]).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enhanced_image=enhanced_image.permute(0,2,3,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1):\n",
    "    with torch.no_grad():\n",
    "        encoded_enhanced = image_encoder.encode(enhanced_image.permute(0,3,1,2))\n",
    "        encoded_input = torch.cat([encoded_source,encoded_enhanced],dim=1)\n",
    "        parameters = agent.actor.get_action(encoded_input)\n",
    "        enhanced_image = photo_editor(original_64.cpu(),parameters[0].cpu())\n",
    "enhanced_image_512 = photo_editor(original_image.cpu(),parameters[0].cpu())\n",
    "parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enhanced_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enhanced =torch.flatten(enhanced_image_512.clone(),start_dim=1, end_dim=-1)\n",
    "target = torch.flatten(original_image.clone(),start_dim=1, end_dim=-1)\n",
    "\n",
    "rmse = enhanced-target\n",
    "rmse = torch.pow(rmse,2).mean(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(enhanced_image_512[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "photoen",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
