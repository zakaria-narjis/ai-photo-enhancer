{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torchrl.data import BoundedTensorSpec\n",
    "from torchrl.modules.distributions.continuous import NormalParamWrapper, TanhNormal\n",
    "from torchrl.modules.tensordict_module.actors import ProbabilisticActor, ValueOperator\n",
    "from torchrl.modules.tensordict_module.common import SafeModule\n",
    "from torchrl.objectives.sac import SACLoss\n",
    "from tensordict import TensorDict\n",
    "from torchrl.objectives.sac import SACLoss\n",
    "from tensordict import TensorDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_act, n_obs = 15,512\n",
    "spec = BoundedTensorSpec(-torch.ones(n_act), torch.ones(n_act), (n_act,))\n",
    "\n",
    "net = NormalParamWrapper(nn.Linear(n_obs, 2 * n_act))\n",
    "module = SafeModule(net, in_keys=[\"observation\"], out_keys=[\"loc\", \"scale\"])\n",
    "actor = ProbabilisticActor(\n",
    "    module=module,\n",
    "    in_keys=[\"loc\", \"scale\"],\n",
    "    spec=spec,\n",
    "    distribution_class=TanhNormal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ValueClass(nn.Module):\n",
    "    def __init__(self,):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(n_obs + n_act, 1)\n",
    "    def forward(self, obs, act):\n",
    "        return self.linear(torch.cat([obs, act], -1))\n",
    "    \n",
    "module = ValueClass()\n",
    "\n",
    "qvalue = ValueOperator(\n",
    "    module=module,\n",
    "    in_keys=['observation', 'action'])\n",
    "\n",
    "loss = SACLoss(actor, qvalue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch = [2, ]\n",
    "# action = spec.rand(batch)\n",
    "# buffer_lazytensor = ReplayBuffer(storage=LazyTensorStorage(size))\n",
    "# from torchrl.envs.transforms import CatTensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tensordict import TensorDict\n",
    "from torchrl.data import ReplayBuffer\n",
    "from torchrl.data.replay_buffers.samplers import PrioritizedSampler\n",
    "from torchrl.data import LazyMemmapStorage, LazyTensorStorage, ListStorage\n",
    "from torchrl.data import TensorDictReplayBuffer\n",
    "from torchrl.data.replay_buffers.samplers import SamplerWithoutReplacement\n",
    "size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchrl.envs.transforms import (\n",
    "    Compose,\n",
    "    GrayScale,\n",
    "    Resize,\n",
    "    ToTensorImage,\n",
    "    TransformedEnv,\n",
    ")\n",
    "a =  Compose(\n",
    "        ToTensorImage(in_keys=[\"pixels\"], out_keys=[\"pixels_trsf\"]),\n",
    "        Resize(in_keys=[\"pixels_trsf\"], w=64, h=64),\n",
    "        GrayScale(in_keys=[\"pixels_trsf\"]),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding testing data ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b195588a2de466fabaeaa42bc1cd625",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished...\n",
      "Encoding training data ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff4362f61be74820985d0ea096fd0372",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/36 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished...\n"
     ]
    }
   ],
   "source": [
    "from envs.photo_env import PhotoEnhancementEnv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "env = PhotoEnhancementEnv(64)\n",
    "state = env.reset()\n",
    "action = torch.rand(64,15)\n",
    "next_state,rewards, dones  = env.step(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchrl.envs.transforms import (\n",
    "    Compose,\n",
    "    GrayScale,\n",
    "    Resize,\n",
    "    ToTensorImage,\n",
    "    TransformedEnv,CatTensors\n",
    ")\n",
    "transform = Compose(\n",
    "    CatTensors(in_keys = [(\"state\",\"encoded_enhanced_image\"),(\"state\",\"encoded_source\")], out_key = ('state','encoded_observation')),\n",
    "    CatTensors(in_keys = [(\"next_state\",\"encoded_enhanced_image\"),(\"next_state\",\"encoded_source\")], out_key = ('next_state','encoded_observation'))\n",
    ")\n",
    "transform = Compose(\n",
    "    CatTensors(in_keys = [\"encoded_enhanced_image\",\"encoded_source\"], out_key = 'encoded_observation'),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "buffer_ = TensorDictReplayBuffer(\n",
    "    storage=LazyMemmapStorage(size,), sampler=SamplerWithoutReplacement()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "transition ={\n",
    "    'state':state,\n",
    "    'action':action,\n",
    "    'next_state':next_state,\n",
    "    'rewards':rewards,\n",
    "    'done':dones,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1-torch.Tensor([True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "new(): data must be a sequence (got bool)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto(torch\u001b[38;5;241m.\u001b[39mfloat32)\n",
      "\u001b[0;31mTypeError\u001b[0m: new(): data must be a sequence (got bool)"
     ]
    }
   ],
   "source": [
    "torch.Tensor(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "a= dones.clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "a[0]=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.to(torch.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dones.to(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "td = TensorDict(transition ,batch_size=[state.shape[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45,\n",
       "        46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63,\n",
       "        64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81,\n",
       "        82, 83, 84, 85, 86, 87, 88, 89, 90, 91])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "buffer_.extend(td)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buffer_.device='cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorDictReplayBuffer(\n",
       "    storage=LazyMemmapStorage(\n",
       "        data=TensorDict(\n",
       "            fields={\n",
       "                action: MemoryMappedTensor(shape=torch.Size([100, 15]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                done: MemoryMappedTensor(shape=torch.Size([100]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "                index: MemoryMappedTensor(shape=torch.Size([100]), device=cpu, dtype=torch.int64, is_shared=False),\n",
       "                next_state: MemoryMappedTensor(shape=torch.Size([100, 1024]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                rewards: MemoryMappedTensor(shape=torch.Size([100]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                state: MemoryMappedTensor(shape=torch.Size([100, 1024]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
       "            batch_size=torch.Size([100]),\n",
       "            device=cpu,\n",
       "            is_shared=False), \n",
       "        shape=torch.Size([100]), \n",
       "        len=100, \n",
       "        max_size=100), \n",
       "    sampler=SamplerWithoutReplacement( 0.0000% sampled), \n",
       "    writer=TensorDictRoundRobinWriter(cursor=92, full_storage=True), \n",
       "    batch_size=None, \n",
       "    collate_fn=<function _collate_id at 0x74fa980d2ac0>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "buffer_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorDict(\n",
       "    fields={\n",
       "        action: Tensor(shape=torch.Size([12, 15]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
       "        done: Tensor(shape=torch.Size([12]), device=cuda:0, dtype=torch.bool, is_shared=True),\n",
       "        index: Tensor(shape=torch.Size([12]), device=cuda:0, dtype=torch.int64, is_shared=True),\n",
       "        next_state: Tensor(shape=torch.Size([12, 1024]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
       "        rewards: Tensor(shape=torch.Size([12]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
       "        state: Tensor(shape=torch.Size([12, 1024]), device=cuda:0, dtype=torch.float32, is_shared=True)},\n",
       "    batch_size=torch.Size([12]),\n",
       "    device=cuda,\n",
       "    is_shared=True)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "buffer_.sample(12).to('cuda')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "photoen",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.1.-1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
