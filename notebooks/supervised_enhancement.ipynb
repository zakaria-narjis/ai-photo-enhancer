{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.io import read_image\n",
    "from torchvision.transforms import v2\n",
    "import os\n",
    "from pathlib import Path\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.notebook import tqdm\n",
    "from kornia import enhance\n",
    "from torchvision import models\n",
    "from torch import nn\n",
    "from torchmetrics import PeakSignalNoiseRatio\n",
    "import pytorch_lightning as pl\n",
    "from torchmetrics.regression import MeanSquaredError as mse\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESIZE = True\n",
    "IMAGE_SIZE= 224\n",
    "BATCH_SIZE = 32\n",
    "DEVICE = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FiveKDataset(Dataset):\n",
    "    \"\"\"\n",
    "    A dataset that reads Adobe5K dataset images\n",
    "    output : tensor of unprocessed images\n",
    "    \"\"\"\n",
    "    def __init__(self, image_size,mode=\"train\", resize= True ):\n",
    "        current_dir = os.getcwd()\n",
    "        dataset_dir = os.path.join(current_dir, \"..\", \"dataset\", \"FiveK\")\n",
    "        if mode =='train':\n",
    "            self.IMGS_PATH = os.path.join(dataset_dir, \"train\")\n",
    "        else:\n",
    "            self.IMGS_PATH = os.path.join(dataset_dir, \"test\")\n",
    "        self.resize= resize\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Resize((image_size,image_size),interpolation= transforms.InterpolationMode.BICUBIC),\n",
    "            transforms.ToTensor(),\n",
    "        ])\n",
    "\n",
    "\n",
    "        self.img_files = [filename for filename in os.listdir(self.IMGS_PATH+'/input/')]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_files)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        source_path = self.img_files[idx]\n",
    "\n",
    "        source = Image.open(self.IMGS_PATH+'/input/'+source_path)\n",
    "        target = Image.open(self.IMGS_PATH+'/target/'+source_path)\n",
    "        if self.resize:\n",
    "            source = self.transform(source)\n",
    "            target = self.transform(target)\n",
    "        # source = self.transform(Image.open(ORIGINAL_FOLDER+source_path))\n",
    "\n",
    "        return source, target "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = FiveKDataset(image_size=IMAGE_SIZE,mode='train',resize=RESIZE)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle = True )\n",
    "test_dataset = FiveKDataset(image_size=IMAGE_SIZE,mode='test',resize=RESIZE)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size= BATCH_SIZE , shuffle = False, num_workers=3)\n",
    "\n",
    "class ResnetEncoder(nn.Module):\n",
    "    def __init__(self,):\n",
    "        super().__init__()\n",
    "        self.model = models.resnet18(weights='ResNet18_Weights.DEFAULT')\n",
    "        self.model = torch.nn.Sequential(*(list(self.model.children())[:-1]))#remove classifier\n",
    "  \n",
    "    def encode(self,images:torch.Tensor)->torch.Tensor:\n",
    "        output = self.model(images)\n",
    "        output = torch.flatten(output,start_dim=-3,end_dim=-1)\n",
    "        return output\n",
    "    \n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self,input_shape=512,output_shape=1):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_shape,256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256,128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128,output_shape)\n",
    "\n",
    "        )\n",
    "    def forward(self,features):\n",
    "        return self.net(features)\n",
    "\n",
    "# class Net(nn.Module):\n",
    "#     def __init__(self,):\n",
    "#         super().__init__()\n",
    "#         self.feature_extractor = ResnetEncoder()\n",
    "#         self.brightness_head = nn.Sequential(\n",
    "#             Classifier(output_shape=1),\n",
    "#             nn.Sigmoid(),\n",
    "#         )\n",
    "\n",
    "#     def forwad(self,images):\n",
    "#         features = self.feature_extractor(images)\n",
    "#         brightness_factor = self.brightness_head(features)\n",
    "#         output = enhance.adjust_brightness(images,brightness_factor)\n",
    "#         return output\n",
    "\n",
    "class Net(pl.LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.feature_extractor = ResnetEncoder()\n",
    "        self.brightness_head = nn.Sequential(\n",
    "            Classifier(output_shape=1),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "        self.psnr = PeakSignalNoiseRatio(data_range=1.0)\n",
    "        self.loss =  mse()\n",
    "        self.normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    def forward(self, images):\n",
    "        features = self.feature_extractor.encode(self.normalize(images))\n",
    "        brightness_factor = self.brightness_head(features)\n",
    "        output = enhance.adjust_brightness(images,brightness_factor)\n",
    "        return output\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        inputs, targets = batch\n",
    "        outputs = self(inputs)\n",
    "        loss = self.loss(outputs, targets)\n",
    "        psnr = self.psnr(outputs, targets)\n",
    "        self.log('train_loss', loss)\n",
    "        self.log('train_psnr', psnr, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        inputs, targets = batch\n",
    "        outputs = self(inputs)\n",
    "        loss = self.loss(outputs, targets)\n",
    "        psnr = self.psnr(outputs, targets)\n",
    "        self.log('val_loss', loss)\n",
    "        self.log('val_psnr', psnr, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n",
    "        return optimizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net()\n",
    "trainer = pl.Trainer(max_epochs=10,accelerator=\"gpu\") # Adjust the number of epochs and GPUs as needed\n",
    "\n",
    "# Train the model\n",
    "trainer.fit(model, train_dataloader, test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "model.eval()\n",
    "with torch.inference_mode():\n",
    "    for i,j in train_dataloader:\n",
    "        output = model(i)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(i[0].permute(1, 2, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(output[0].permute(1,2,0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
