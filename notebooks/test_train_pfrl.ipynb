{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import distributions, nn\n",
    "import pfrl\n",
    "from pfrl import experiments, replay_buffers, utils\n",
    "from pfrl.nn.lmbda import Lambda\n",
    "from pfrl.nn import BoundByTanh, ConcatObsAndAction\n",
    "import yaml\n",
    "import time\n",
    "import random \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"configs/hyperparameters.yaml\") as f:\n",
    "    config_dict =yaml.load(f, Loader=yaml.FullLoader)\n",
    "    \n",
    "class Config(object):\n",
    "    def __init__(self, dictionary):\n",
    "        self.__dict__.update(dictionary)\n",
    "sac_config = Config(config_dict)\n",
    "\n",
    "SEED = sac_config.seed\n",
    "DEVICE= 'CUDA'\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = sac_config.torch_deterministic\n",
    "torch.autograd.set_detect_anomaly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_options = {\n",
    "    'gamma':0.9,\n",
    "    'minibatch_size':124,\n",
    "    'tau':0.005,\n",
    "    'replay_memory_size':40000\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_agent_sac(state_size,action_size,config=sac_config,gpu=0):\n",
    "    def squashed_diagonal_gaussian_head(x):\n",
    "        assert x.shape[-1] == action_size * 2\n",
    "        mean, log_scale = torch.chunk(x, 2, dim=1)\n",
    "        log_scale = torch.clamp(log_scale, -20.0, 2.0)\n",
    "        var = torch.exp(log_scale * 2)\n",
    "        base_distribution = distributions.Independent(\n",
    "            distributions.Normal(loc=mean, scale=torch.sqrt(var)), 1\n",
    "        )\n",
    "        # cache_size=1 is required for numerical stability\n",
    "        return distributions.transformed_distribution.TransformedDistribution(\n",
    "            base_distribution, [distributions.transforms.TanhTransform(cache_size=1)]\n",
    "        )\n",
    "\n",
    "\n",
    "    #critic_networks\n",
    "    q_func_1 = nn.Sequential(\n",
    "        ConcatObsAndAction(),\n",
    "        nn.Linear(state_size + action_size, 256),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(256, 256),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(256, 1),\n",
    "    )\n",
    "    q_func_2 = nn.Sequential(\n",
    "        ConcatObsAndAction(),\n",
    "        nn.Linear(state_size + action_size, 256),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(256, 256),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(256, 1),\n",
    "    )\n",
    "    \n",
    "    #actor_network\n",
    "    policy = nn.Sequential(\n",
    "        nn.Linear(state_size, 256),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(256, 256),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(256, action_size* 2),\n",
    "        pfrl.nn.lmbda.Lambda(squashed_diagonal_gaussian_head),\n",
    "    )\n",
    "\n",
    "\n",
    "    opt_a = torch.optim.Adam(policy.parameters(), lr=config.policy_lr)\n",
    "    opt_c_1 = torch.optim.Adam(q_func_1.parameters(), lr=config.q_lr)\n",
    "    opt_c_2 = torch.optim.Adam(q_func_2.parameters(), lr=config.q_lr)\n",
    "    \n",
    "    rbuf = replay_buffers.ReplayBuffer(sac_config.buffer_size)\n",
    "\n",
    "    agent = pfrl.agents.SoftActorCritic(\n",
    "        policy,\n",
    "        q_func_1,\n",
    "        q_func_2,\n",
    "        opt_a,\n",
    "        opt_c_1,\n",
    "        opt_c_2,\n",
    "        rbuf,\n",
    "        gamma= config.buffer_size,\n",
    "        update_interval=1,\n",
    "        replay_start_size=config.learning_starts*64,\n",
    "        gpu=gpu,\n",
    "        soft_update_tau= config.tau,\n",
    "        minibatch_size = config.batch_size,\n",
    "        entropy_target=-action_size,\n",
    "        temperature_optimizer_lr=config.q_lr,\n",
    "    )\n",
    "    return agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from envs.photo_env import PhotoEnhancementEnv\n",
    "from envs.photo_env import PhotoEnhancementEnvTest\n",
    "env = PhotoEnhancementEnv()\n",
    "test_env = PhotoEnhancementEnvTest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "run_name = f\"{sac_config.exp_name}__{sac_config.seed}__{int(time.time())}\"\n",
    "writer = SummaryWriter(f\"runs/{run_name}\")\n",
    "writer.add_text(\n",
    "    \"hyperparameters\",\n",
    "    \"|param|value|\\n|-|-|\\n%s\" % (\"\\n\".join([f\"|{key}|{value}|\" for key, value in vars(sac_config).items()])),\n",
    ")\n",
    "\n",
    "agent = create_agent_sac(512,env.num_parameters,train_options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_step = 0\n",
    "start_time = time.time()\n",
    "for i in range(sac_config.total_timesteps):\n",
    "    episode_count = 0\n",
    "    agent.training=True\n",
    "    obs = env.reset()\n",
    "    envs_mean_rewards =[]\n",
    "    while True:     \n",
    "        episode_count+=1\n",
    "        global_step+=1\n",
    "        batch_actions = torch.tensor(agent.batch_act(obs))\n",
    "        next_obs,rewards,batch_dones = env.step(batch_actions)\n",
    "        envs_mean_rewards.append(rewards)\n",
    "        batch_reset = [False for i in range(len(batch_dones))]\n",
    "        agent.batch_observe(next_obs ,rewards,batch_dones,batch_reset)\n",
    "        obs=next_obs\n",
    "        \n",
    "        if(batch_dones==True).any():\n",
    "            print('one done')\n",
    "            print(env.sub_env_running)\n",
    "\n",
    "        if  global_step % 100 == 0:\n",
    "            writer.add_scalar(\"charts/mean_episodic_return\", ens_mean_episodic_return, global_step)\n",
    "            print(\"SPS:\", int(global_step / (time.time() - start_time)))\n",
    "            stats = agent.get_statistics()\n",
    "            for stat in stats:\n",
    "                writer.add_scalar(f\"charts/{stat[0]}\", stat[1], global_step)   \n",
    "        if (batch_dones==True).all()==True or episode_count==sac_config.max_episode_timesteps:\n",
    "            ens_mean_episodic_return = np.mean(envs_mean_rewards)\n",
    "            envs_mean_rewards =[]  \n",
    "            break \n",
    "\n",
    "    if global_step%200==0:\n",
    "        agent.training=False\n",
    "        with torch.no_grad():\n",
    "            n_images = 10\n",
    "            obs = test_env.reset() \n",
    "            batch_actions = torch.tensor(agent.batch_act(obs))\n",
    "            _,rewards,_ = test_env.step(batch_actions)\n",
    "            writer.add_scalar(\"charts/test_mean_episodic_return\", rewards.mean().item(), global_step)\n",
    "            writer.add_images(\"test_images\",test_env.state['source_image'][:n_images],0)\n",
    "            writer.add_images(\"test_images\",test_env.state['enhanced_image'][:n_images],1)\n",
    "            writer.add_images(\"test_images\",test_env.state['target_image'][:n_images],2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# for i in range(EPISODES):\n",
    "#     obs = env.reset()\n",
    "#     obs=[obs]\n",
    "#     episode_count = 0\n",
    "#     while True:\n",
    "#         encoded_source_image = obs[0]['encoded_source']\n",
    "#         encoded_enhanced_image = obs[0]['encoded_enhanced_image']\n",
    "#         batch_observation = torch.cat((encoded_source_image,encoded_enhanced_image),dim=1)\n",
    "#         batch_actions = torch.tensor(agent.batch_act(batch_observation))\n",
    "\n",
    "\n",
    "#         obs = env.step(batch_actions)\n",
    "#         encoded_source_image = obs[0]['encoded_source']\n",
    "#         encoded_enhanced_image = obs[0]['encoded_enhanced_image']\n",
    "#         batch_observation = torch.cat((encoded_source_image,encoded_enhanced_image),dim=1)\n",
    "#         batch_rewards =  obs[1]\n",
    "#         batch_done = obs[2]\n",
    "#         batch_reset = [False for i in range(len(batch_done))]\n",
    "#         agent.batch_observe(batch_observation ,batch_rewards,batch_done,batch_reset)\n",
    "#         episode_count+=1\n",
    "#         if (batch_done==True).all()==True or episode_count==10:\n",
    "#             print(batch_rewards)\n",
    "#             break      "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "photoen",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
