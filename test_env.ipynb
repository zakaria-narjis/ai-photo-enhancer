{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from torchvision.transforms.functional import adjust_contrast\n",
    "a= torch.rand(64,64, 3) # N H W C\n",
    "input = torch.stack([a,a])\n",
    "parameters = torch.Tensor([0.5,0.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(x):\n",
    "    x_ = x.copy()\n",
    "    x_[x_<0] = 0\n",
    "    return x_\n",
    "\n",
    "class AdjustContraste():\n",
    "    def __init__(self):\n",
    "        self.num_parameters = 1\n",
    "        self.window_names = [\"parameter\"]\n",
    "        self.slider_names = [\"contrast\"]\n",
    "\n",
    "    def __call__(self, list_editted, parameters):     \n",
    "        editted  =  list_editted.numpy()\n",
    "        mean = editted.mean()\n",
    "        editted_ = (editted-mean)*(parameters[0]+1)+mean\n",
    "        editted_ = relu(editted_)\n",
    "        editted_ = 1-relu(1-editted_)\n",
    "        return [editted_]\n",
    "    \n",
    "old = AdjustContraste()(a,[0.5])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdjustContrast():\n",
    "    def __init__(self):\n",
    "        self.num_parameters = 1\n",
    "        self.window_names = [\"parameter\"]\n",
    "        self.slider_names = [\"contrast\"]\n",
    "\n",
    "    def __call__(self, images:torch.Tensor, parameters:torch.Tensor):\n",
    "        batch_size = parameters.shape[0]\n",
    "        mean = images.view(batch_size,-1).mean(1)\n",
    "        mean = mean.view(batch_size, 1, 1, 1)\n",
    "        parameters = parameters.view(batch_size, 1, 1, 1)\n",
    "        editted = (images-mean)*(parameters+1)+mean\n",
    "        editted = F.relu(editted)\n",
    "        editted = 1-F.relu(1-editted)\n",
    "        return editted\n",
    "new = AdjustContrast()(input,torch.Tensor([0.5,0.5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.True_"
      ]
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(old==new[0].numpy()).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "from envs.dehaze.src import dehaze\n",
    "\n",
    "class AdjustDehazee():\n",
    "    def __init__(self):\n",
    "        self.num_parameters = 1\n",
    "        self.window_names = [\"parameter\"]\n",
    "        self.slider_names = [\"dehaze\"]\n",
    "\n",
    "    def __call__(self, list_editted, parameters):\n",
    "        editted = list_editted.numpy()\n",
    "        scale = max((editted.shape[:2])) / 512.0\n",
    "        omega = parameters[0]\n",
    "        editted_ = dehaze.DarkPriorChannelDehaze(\n",
    "            wsize=int(15*scale), radius=int(80*scale), omega=omega,\n",
    "            t_min=0.25, refine=True)(editted * 255.0) / 255.0\n",
    "        editted_ = relu(editted_)\n",
    "        editted_ = 1-relu(1-editted_)\n",
    "        return [editted_]\n",
    "old = AdjustDehazee()(a,[0.5])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdjustDehaze():\n",
    "\n",
    "    def __init__(self):\n",
    "        self.num_parameters = 1\n",
    "        self.window_names = [\"parameter\"]\n",
    "        self.slider_names = [\"dehaze\"]\n",
    "\n",
    "    def __call__(self, images, parameters):\n",
    "        \"\"\"\n",
    "        Takes a batch of images where B (the last dim) is the batch size\n",
    "        args:\n",
    "            images: torch.Tensor # B H W C \n",
    "            parameters :torch.Tensor # N\n",
    "        return:\n",
    "            output: torch.Tensor #  B H W C \n",
    "        \"\"\"\n",
    "        assert images.dim()==4\n",
    "        batch_size = parameters.shape[0]\n",
    "        output = []\n",
    "        for image_index in range(batch_size):\n",
    "            image = images[image_index].numpy()\n",
    "            scale = max((image.shape[:2])) / 512.0\n",
    "            omega = float(parameters[image_index])\n",
    "            editted= dehaze.DarkPriorChannelDehaze(\n",
    "                wsize=int(15*scale), radius=int(80*scale), omega=omega,\n",
    "                t_min=0.25, refine=True)(image * 255.0) / 255.0\n",
    "            editted = torch.tensor(editted)\n",
    "            editted = F.relu(editted)\n",
    "            editted= 1-F.relu(1-editted)\n",
    "            output.append(editted)\n",
    "        output = torch.stack(output)\n",
    "        return output\n",
    "    \n",
    "    \n",
    "new = AdjustDehaze()(input,parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.True_"
      ]
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(old==new.numpy()[0]).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "class AdjustClaritye():\n",
    "    def __init__(self):\n",
    "        self.num_parameters = 1\n",
    "        self.window_names = [\"parameter\"]\n",
    "        self.slider_names = [\"clarity\"]\n",
    "\n",
    "    def __call__(self, list_editted, parameters):\n",
    "        editted = list_editted.numpy()\n",
    "        scale = max((editted.shape[:2])) / 512.0\n",
    "        clarity = parameters[0]\n",
    "\n",
    "        unsharped = cv2.bilateralFilter((editted*255.0).astype(np.uint8),\n",
    "                                            int(32*scale), 50, 10*scale)/255.0\n",
    "        editted_ = editted + (editted-unsharped) * clarity\n",
    "        return [editted_]\n",
    "    \n",
    "old = AdjustClaritye()(a,[0.5])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class AdjustClarity():\n",
    "    def __init__(self):\n",
    "        self.num_parameters = 1\n",
    "        self.window_names = [\"parameter\"]\n",
    "        self.slider_names = [\"clarity\"]\n",
    "\n",
    "    def __call__(self, images, parameters):\n",
    "        \"\"\"\n",
    "        Takes a batch of images where B (the last dim) is the batch size\n",
    "        args:\n",
    "            images: torch.Tensor # B H W C \n",
    "            parameters :torch.Tensor # N\n",
    "        return:\n",
    "            output: torch.Tensor #  B H W C \n",
    "        \"\"\"\n",
    "        assert images.dim()==4\n",
    "        batch_size = parameters.shape[0]\n",
    "        output = [] \n",
    "        clarity = parameters.view(batch_size, 1, 1, 1)\n",
    "        for image in images: \n",
    "            input = image.numpy()      \n",
    "            scale = max((input.shape[:2])) / 512.0\n",
    "            unsharped = cv2.bilateralFilter((input*255.0).astype(np.uint8),\n",
    "                                                int(32*scale), 50, 10*scale)/255.0\n",
    "            output.append(torch.tensor(unsharped))\n",
    "        output = torch.stack(output) \n",
    "        editted_images = images + (images-output) * clarity\n",
    "        \n",
    "        return editted_images\n",
    "    \n",
    "# class AdjustClarity():\n",
    "#     def __init__(self):\n",
    "#         self.num_parameters = 1\n",
    "#         self.window_names = [\"parameter\"]\n",
    "#         self.slider_names = [\"clarity\"]\n",
    "\n",
    "#     def __call__(self, images, parameters):\n",
    "#         assert images.dim()==4\n",
    "#         batch_size = parameters.shape[0]\n",
    "#         output = [] \n",
    "        \n",
    "#         for image_index,image in enumerate(images): \n",
    "#             clarity = float(parameters[image_index])\n",
    "#             input = image.numpy()      \n",
    "#             scale = max((input.shape[:2])) / 512.0\n",
    "#             unsharped = cv2.bilateralFilter((input*255.0).astype(np.uint8),\n",
    "#                                                 int(32*scale), 50, 10*scale)/255.0\n",
    "#             editted = input + (input-unsharped) * clarity\n",
    "#             output.append(torch.tensor(editted))\n",
    "\n",
    "#         output = torch.stack(output) \n",
    "\n",
    "#         return output\n",
    "new = AdjustClarity()(input,parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.True_"
      ]
     },
     "execution_count": 455,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(old==new.numpy()[1]).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# exposure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 636,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_inverse(y):\n",
    "    epsilon = 10**(-3)\n",
    "    y = F.relu(y-epsilon)+epsilon\n",
    "    y = 1-epsilon-F.relu((1-epsilon)-y)\n",
    "    y = (1/y)-1\n",
    "    output = -np.log(y.numpy())\n",
    "    return torch.tensor(output)\n",
    "\n",
    "class SigmoidInverse():\n",
    "\n",
    "    def __init__(self):\n",
    "        self.num_parameters = 0\n",
    "\n",
    "    def __call__(self, images):\n",
    "        return sigmoid_inverse(images)\n",
    "new_sig_inv = SigmoidInverse()\n",
    "\n",
    "def old_sigmoid_inverse(y):\n",
    "    epsilon = 10**(-3)\n",
    "    y_ = y.copy()\n",
    "    y_ = relu(y_-epsilon)+epsilon\n",
    "    y_ = 1-epsilon-relu((1-epsilon)-y_)\n",
    "    y_ = (1/y_)-1\n",
    "    output = -np.log(y_)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 637,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.True_"
      ]
     },
     "execution_count": 637,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(old_sigmoid_inverse(a.numpy())==new_sig_inv (input)[0].numpy()).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 638,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdjustExposuree():\n",
    "    def __init__(self):\n",
    "        self.num_parameters = 1\n",
    "        self.window_names = [\"parameter\"]\n",
    "        self.slider_names = [\"exposure\"]\n",
    "\n",
    "    def __call__(self, list_sigmoid_inversed, parameters):\n",
    "        exposure = parameters[0]\n",
    "        return [old_sigmoid_inverse(list_sigmoid_inversed)+ exposure*5]\n",
    "old = AdjustExposuree()(a.numpy(),[0.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdjustExposure():\n",
    "    def __init__(self):\n",
    "        self.num_parameters = 1\n",
    "        self.window_names = [\"parameter\"]\n",
    "        self.slider_names = [\"exposure\"]\n",
    "\n",
    "    def __call__(self, list_sigmoid_inversed, parameters):\n",
    "        exposure = parameters[0]\n",
    "        return [list_sigmoid_inversed[0] + exposure*5]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "photoen",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
