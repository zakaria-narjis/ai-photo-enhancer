{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torchrl.data import BoundedTensorSpec\n",
    "from torchrl.modules.distributions.continuous import NormalParamWrapper, TanhNormal\n",
    "from torchrl.modules.tensordict_module.actors import ProbabilisticActor, ValueOperator\n",
    "from torchrl.modules.tensordict_module.common import SafeModule\n",
    "from torchrl.objectives.sac import SACLoss\n",
    "from tensordict import TensorDict\n",
    "from torchrl.objectives.sac import SACLoss\n",
    "from tensordict import TensorDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_act, n_obs = 15,512\n",
    "spec = BoundedTensorSpec(-torch.ones(n_act), torch.ones(n_act), (n_act,))\n",
    "\n",
    "net = NormalParamWrapper(nn.Linear(n_obs, 2 * n_act))\n",
    "module = SafeModule(net, in_keys=[\"observation\"], out_keys=[\"loc\", \"scale\"])\n",
    "actor = ProbabilisticActor(\n",
    "    module=module,\n",
    "    in_keys=[\"loc\", \"scale\"],\n",
    "    spec=spec,\n",
    "    distribution_class=TanhNormal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ValueClass(nn.Module):\n",
    "    def __init__(self,):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(n_obs + n_act, 1)\n",
    "    def forward(self, obs, act):\n",
    "        return self.linear(torch.cat([obs, act], -1))\n",
    "    \n",
    "module = ValueClass()\n",
    "\n",
    "qvalue = ValueOperator(\n",
    "    module=module,\n",
    "    in_keys=['observation', 'action'])\n",
    "\n",
    "loss = SACLoss(actor, qvalue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch = [2, ]\n",
    "# action = spec.rand(batch)\n",
    "# buffer_lazytensor = ReplayBuffer(storage=LazyTensorStorage(size))\n",
    "# from torchrl.envs.transforms import CatTensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tensordict import TensorDict\n",
    "from torchrl.data import ReplayBuffer\n",
    "from torchrl.data.replay_buffers.samplers import PrioritizedSampler\n",
    "from torchrl.data import LazyMemmapStorage, LazyTensorStorage, ListStorage\n",
    "from torchrl.data import TensorDictReplayBuffer\n",
    "from torchrl.data.replay_buffers.samplers import SamplerWithoutReplacement\n",
    "size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchrl.envs.transforms import (\n",
    "    Compose,\n",
    "    GrayScale,\n",
    "    Resize,\n",
    "    ToTensorImage,\n",
    "    TransformedEnv,\n",
    ")\n",
    "a =  Compose(\n",
    "        ToTensorImage(in_keys=[\"pixels\"], out_keys=[\"pixels_trsf\"]),\n",
    "        Resize(in_keys=[\"pixels_trsf\"], w=64, h=64),\n",
    "        GrayScale(in_keys=[\"pixels_trsf\"]),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding testing data ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6edb34015e834e68abb23a8e6d322409",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished...\n",
      "Encoding training data ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24deeb716efd4734a7578897d0aca3a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/36 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished...\n"
     ]
    }
   ],
   "source": [
    "from envs.photo_env import PhotoEnhancementEnv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "env = PhotoEnhancementEnv(64)\n",
    "state = env.reset()\n",
    "action = torch.rand(64,15)\n",
    "next_state,rewards, dones  = env.step(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchrl.envs.transforms import (\n",
    "    Compose,\n",
    "    GrayScale,\n",
    "    Resize,\n",
    "    ToTensorImage,\n",
    "    TransformedEnv,CatTensors\n",
    ")\n",
    "transform = Compose(\n",
    "    CatTensors(in_keys = [(\"state\",\"encoded_enhanced_image\"),(\"state\",\"encoded_source\")], out_key = ('state','encoded_observation')),\n",
    "    CatTensors(in_keys = [(\"next_state\",\"encoded_enhanced_image\"),(\"next_state\",\"encoded_source\")], out_key = ('next_state','encoded_observation'))\n",
    ")\n",
    "transform = Compose(\n",
    "    CatTensors(in_keys = [\"encoded_enhanced_image\",\"encoded_source\"], out_key = 'encoded_observation'),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "buffer_ = TensorDictReplayBuffer(\n",
    "    storage=LazyMemmapStorage(size,), sampler=SamplerWithoutReplacement()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "transition ={\n",
    "    'state':state,\n",
    "    'action':action,\n",
    "    'next_state':next_state,\n",
    "    'rewards':rewards,\n",
    "    'done':dones,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "td = TensorDict(transition ,batch_size=[state.shape[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81,\n",
       "        82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99,\n",
       "         0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "buffer_.extend(td)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-0.4233)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rewards.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorDict(\n",
       "    fields={\n",
       "        action: Tensor(shape=torch.Size([12, 15]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "        done: Tensor(shape=torch.Size([12]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "        index: Tensor(shape=torch.Size([12]), device=cpu, dtype=torch.int64, is_shared=False),\n",
       "        next_state: Tensor(shape=torch.Size([12, 1024]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "        rewards: Tensor(shape=torch.Size([12]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "        state: Tensor(shape=torch.Size([12, 1024]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
       "    batch_size=torch.Size([12]),\n",
       "    device=cpu,\n",
       "    is_shared=False)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "buffer_.sample(12)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "photoen",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
